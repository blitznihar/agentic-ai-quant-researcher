{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612d1e52",
   "metadata": {},
   "source": [
    "# 05_agentic_evaluation_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109f40b",
   "metadata": {},
   "source": [
    "05 — Agentic Evaluation Loop (Routing, Workers, Evaluator–Optimizer, Self-Reflection)\n",
    "Goal: Treat quant research as an agent workflow:\n",
    "\n",
    "Route question → pick workflow\n",
    "\n",
    "Generate multiple strategy variants in parallel\n",
    "\n",
    "Evaluate and select best candidate under risk constraints\n",
    "\n",
    "Produce an audit-friendly research memo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf6346",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PROCESSED = os.path.join(REPO_ROOT, \"data\", \"processed\")\n",
    "REPORTS = os.path.join(REPO_ROOT, \"reports\")\n",
    "os.makedirs(REPORTS, exist_ok=True)\n",
    "\n",
    "signals_path = os.path.join(DATA_PROCESSED, \"signals.parquet\")\n",
    "assert os.path.exists(signals_path), f\"Missing {signals_path}. Run Notebook 03 first.\"\n",
    "\n",
    "df = pd.read_parquet(signals_path)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values([\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "# Add returns if not present\n",
    "if \"ret\" not in df.columns:\n",
    "    df[\"ret\"] = df.groupby(\"ticker\")[\"adj_close\"].pct_change().fillna(0.0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bcf85",
   "metadata": {},
   "source": [
    "### Core “backtest engine” helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRADING_DAYS = 252\n",
    "\n",
    "def portfolio_returns_from_weights(df, weight_col, ret_col=\"ret\"):\n",
    "    return df.groupby(\"date\").apply(lambda g: np.sum(g[weight_col].values * g[ret_col].values))\n",
    "\n",
    "def daily_turnover_from_weights(df, weight_col):\n",
    "    w = df.pivot(index=\"date\", columns=\"ticker\", values=weight_col).fillna(0.0)\n",
    "    turnover = 0.5 * w.diff().abs().sum(axis=1)\n",
    "    return turnover\n",
    "\n",
    "def drawdown_series(returns):\n",
    "    eq = (1 + returns).cumprod()\n",
    "    peak = eq.cummax()\n",
    "    return eq/peak - 1\n",
    "\n",
    "def perf_stats(returns):\n",
    "    returns = returns.fillna(0.0)\n",
    "    eq = (1 + returns).cumprod()\n",
    "    total_return = eq.iloc[-1] - 1.0\n",
    "    cagr = (eq.iloc[-1]) ** (TRADING_DAYS / len(eq)) - 1.0 if len(eq) else np.nan\n",
    "\n",
    "    vol = returns.std() * np.sqrt(TRADING_DAYS)\n",
    "    sharpe = (returns.mean() / returns.std()) * np.sqrt(TRADING_DAYS) if returns.std() != 0 else np.nan\n",
    "\n",
    "    downside = returns[returns < 0].std() * np.sqrt(TRADING_DAYS)\n",
    "    sortino = (returns.mean() / returns[returns < 0].std()) * np.sqrt(TRADING_DAYS) if returns[returns < 0].std() != 0 else np.nan\n",
    "\n",
    "    dd = drawdown_series(returns)\n",
    "    mdd = dd.min()\n",
    "    calmar = cagr / abs(mdd) if mdd != 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"total_return\": total_return,\n",
    "        \"cagr\": cagr,\n",
    "        \"volatility\": vol,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"sortino\": sortino,\n",
    "        \"max_drawdown\": mdd,\n",
    "        \"calmar\": calmar,\n",
    "        \"win_rate_daily\": (returns > 0).mean(),\n",
    "        \"days\": len(eq)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdf241",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_intent(user_question: str) -> str:\n",
    "    q = user_question.lower()\n",
    "    if any(k in q for k in [\"drawdown\", \"risk\", \"volatility\", \"max dd\", \"turnover\", \"cost\", \"slippage\"]):\n",
    "        return \"risk_review\"\n",
    "    if any(k in q for k in [\"fundamental\", \"valuation\", \"quality\", \"growth\", \"pe\", \"margin\"]):\n",
    "        return \"fundamentals_workflow\"\n",
    "    if any(k in q for k in [\"candlestick\", \"stochastic\", \"ema\", \"technical\", \"momentum\", \"oversold\"]):\n",
    "        return \"technical_workflow\"\n",
    "    if any(k in q for k in [\"hybrid\", \"combine\", \"timing\", \"select then time\"]):\n",
    "        return \"hybrid_workflow\"\n",
    "    return \"hybrid_workflow\"  # sensible default\n",
    "\n",
    "# Example\n",
    "question = \"Find a robust hybrid strategy with low drawdown and reasonable turnover.\"\n",
    "intent = route_intent(question)\n",
    "intent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48928f0a",
   "metadata": {},
   "source": [
    "### Worker: Strategy variant generator (pure TA + optional candle confirm)\n",
    "\n",
    "Instead of re-running Notebook 03 logic, we regenerate TA weights in Notebook 5 for parameter sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ta_weights(df, oversold_th=20, use_candle_confirm=True, use_trend_filter=True):\n",
    "    # required columns\n",
    "    needed = [\"stoch_k_14\",\"stoch_d_14_3\",\"ema20\",\"adj_close\",\"is_hammer\",\"is_bull_engulf\"]\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns for TA generation: {missing}\")\n",
    "\n",
    "    g = df.groupby(\"ticker\", group_keys=False)\n",
    "    k = df[\"stoch_k_14\"]\n",
    "    d = df[\"stoch_d_14_3\"]\n",
    "    k_prev = g[\"stoch_k_14\"].shift(1)\n",
    "    d_prev = g[\"stoch_d_14_3\"].shift(1)\n",
    "\n",
    "    cross_up = (k_prev < d_prev) & (k > d)\n",
    "    oversold = (k_prev < oversold_th)\n",
    "    trend_ok = (df[\"adj_close\"] > df[\"ema20\"]) if use_trend_filter else True\n",
    "    bull_candle = (df[\"is_hammer\"] == 1) | (df[\"is_bull_engulf\"] == 1)\n",
    "\n",
    "    entry = cross_up & oversold & trend_ok\n",
    "    if use_candle_confirm:\n",
    "        entry = entry & bull_candle\n",
    "\n",
    "    # exit: trend break or stoch overbought\n",
    "    exit_sig = (df[\"adj_close\"] < df[\"ema20\"]) | (k > 80)\n",
    "\n",
    "    # build position per ticker\n",
    "    pos = []\n",
    "    for tkr, gg in df.groupby(\"ticker\"):\n",
    "        in_pos = 0\n",
    "        for _, r in gg.iterrows():\n",
    "            if in_pos == 0 and bool(entry.loc[r.name]):\n",
    "                in_pos = 1\n",
    "            elif in_pos == 1 and bool(exit_sig.loc[r.name]):\n",
    "                in_pos = 0\n",
    "            pos.append(in_pos)\n",
    "\n",
    "    pos = pd.Series(pos, index=df.index)\n",
    "    member = (pos == 1).astype(int)\n",
    "    count = df.groupby(\"date\")[\"date\"].transform(lambda s: np.nan)  # placeholder\n",
    "    \n",
    "    # equal-weight among active TA positions\n",
    "    active = member.groupby(df[\"date\"]).transform(\"sum\").replace(0, np.nan)\n",
    "    w = np.where(member == 1, 1.0 / active, 0.0)\n",
    "    w = np.nan_to_num(w, nan=0.0)\n",
    "    return pd.Series(w, index=df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a89398",
   "metadata": {},
   "source": [
    "### Worker: Fundamentals selection variants (Top N)\n",
    "\n",
    "We’ll sweep TOP_N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fund_weights(df, top_n=10):\n",
    "    if \"fundamental_score\" not in df.columns:\n",
    "        raise ValueError(\"Missing fundamental_score\")\n",
    "\n",
    "    # Use monthly selection logic (first trading day of month)\n",
    "    tmp = df.copy()\n",
    "    tmp[\"month\"] = tmp[\"date\"].dt.to_period(\"M\")\n",
    "    tmp[\"has_fund\"] = tmp[\"fundamental_score\"].notna().astype(int)\n",
    "\n",
    "    first_of_month = (\n",
    "        tmp[tmp[\"has_fund\"] == 1]\n",
    "        .sort_values([\"ticker\",\"date\"])\n",
    "        .groupby([\"ticker\",\"month\"], as_index=False)\n",
    "        .first()\n",
    "    )\n",
    "    first_of_month[\"rank\"] = first_of_month.groupby(\"month\")[\"fundamental_score\"].rank(ascending=False, method=\"first\")\n",
    "    first_of_month[\"sel\"] = (first_of_month[\"rank\"] <= top_n).astype(int)\n",
    "\n",
    "    tmp = tmp.merge(first_of_month[[\"ticker\",\"month\",\"sel\"]], on=[\"ticker\",\"month\"], how=\"left\")\n",
    "    tmp[\"sel\"] = tmp[\"sel\"].fillna(0).astype(int)\n",
    "\n",
    "    count = tmp.groupby(\"date\")[\"sel\"].transform(\"sum\").replace(0, np.nan)\n",
    "    w = np.where(tmp[\"sel\"] == 1, 1.0 / count, 0.0)\n",
    "    w = np.nan_to_num(w, nan=0.0)\n",
    "    return pd.Series(w, index=df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89f741",
   "metadata": {},
   "source": [
    "### Hybrid worker: selection + TA timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hybrid_weights(df, top_n=10, oversold_th=20, use_candle_confirm=True, use_trend_filter=True):\n",
    "    w_fund = generate_fund_weights(df, top_n=top_n)\n",
    "    w_ta = generate_ta_weights(df, oversold_th=oversold_th, use_candle_confirm=use_candle_confirm, use_trend_filter=use_trend_filter)\n",
    "\n",
    "    # Convert weights to membership\n",
    "    fund_member = (w_fund > 0).astype(int)\n",
    "    ta_member = (w_ta > 0).astype(int)\n",
    "\n",
    "    hybrid_member = (fund_member & ta_member).astype(int)\n",
    "    count = hybrid_member.groupby(df[\"date\"]).transform(\"sum\").replace(0, np.nan)\n",
    "    w = np.where(hybrid_member == 1, 1.0 / count, 0.0)\n",
    "    w = np.nan_to_num(w, nan=0.0)\n",
    "    return pd.Series(w, index=df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168b3b9",
   "metadata": {},
   "source": [
    "### Evaluator: scoring function\n",
    "\n",
    "Score candidates with a balanced objective:\n",
    "\n",
    "- reward Sharpe & CAGR\n",
    "- penalize Max Drawdown and high Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efcae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate(df, weights, cost_bps=5):\n",
    "    cost_rate = cost_bps / 10000.0\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"w\"] = weights.values\n",
    "\n",
    "    port = portfolio_returns_from_weights(tmp, \"w\")\n",
    "    turnover = daily_turnover_from_weights(tmp, \"w\")\n",
    "    net = port - cost_rate * turnover\n",
    "\n",
    "    stats = perf_stats(net)\n",
    "    stats[\"avg_turnover\"] = turnover.mean()\n",
    "    stats[\"median_turnover\"] = turnover.median()\n",
    "\n",
    "    # Composite score (tunable)\n",
    "    # Higher is better:\n",
    "    # - Sharpe and CAGR positive contribution\n",
    "    # - Drawdown and turnover negative\n",
    "    score = (\n",
    "        2.0 * (stats[\"sharpe\"] if not np.isnan(stats[\"sharpe\"]) else -5) +\n",
    "        1.0 * (stats[\"cagr\"] if not np.isnan(stats[\"cagr\"]) else -5) +\n",
    "        1.5 * (stats[\"max_drawdown\"]) -   # max_drawdown is negative\n",
    "        0.5 * (stats[\"avg_turnover\"])\n",
    "    )\n",
    "    stats[\"score\"] = score\n",
    "    return net, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb5323",
   "metadata": {},
   "source": [
    "### Parallel workers: run a small grid search\n",
    "\n",
    "This is your worker orchestration + parallelization section. (We keep it sequential for simplicity, but conceptually it’s parallel workers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1aa2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"top_n\": [5, 10, 15],\n",
    "    \"oversold_th\": [10, 20, 30],\n",
    "    \"use_candle_confirm\": [True, False],\n",
    "    \"use_trend_filter\": [True, False]\n",
    "}\n",
    "\n",
    "candidates = []\n",
    "returns_store = {}\n",
    "\n",
    "for top_n, th, candle, trend in itertools.product(\n",
    "    grid[\"top_n\"], grid[\"oversold_th\"], grid[\"use_candle_confirm\"], grid[\"use_trend_filter\"]\n",
    "):\n",
    "    w = generate_hybrid_weights(df, top_n=top_n, oversold_th=th, use_candle_confirm=candle, use_trend_filter=trend)\n",
    "    net, stats = evaluate_candidate(df, w, cost_bps=5)\n",
    "\n",
    "    key = f\"hyb_top{top_n}_th{th}_c{int(candle)}_t{int(trend)}\"\n",
    "    stats.update({\"candidate\": key, \"top_n\": top_n, \"oversold_th\": th, \"candle_confirm\": candle, \"trend_filter\": trend})\n",
    "    candidates.append(stats)\n",
    "    returns_store[key] = net\n",
    "\n",
    "results = pd.DataFrame(candidates).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "results.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3cb4d",
   "metadata": {},
   "source": [
    "### Optimizer: pick best + explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = results.iloc[0].to_dict()\n",
    "best_key = best[\"candidate\"]\n",
    "best_returns = returns_store[best_key]\n",
    "\n",
    "print(\"BEST CANDIDATE:\", best_key)\n",
    "best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b115be7f",
   "metadata": {},
   "source": [
    "Plot best equity curve + drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = (1 + best_returns).cumprod()\n",
    "dd = drawdown_series(best_returns)\n",
    "\n",
    "eq.plot(figsize=(12,4), title=f\"Best Candidate Equity Curve (net) — {best_key}\")\n",
    "plt.show()\n",
    "\n",
    "dd.plot(figsize=(12,3), title=f\"Best Candidate Drawdown — {best_key}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781a74f",
   "metadata": {},
   "source": [
    "### Self-reflection checks\n",
    "\n",
    "These are lightweight but important. Recruiters love seeing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04152085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_reflection_checks(df, weights_row_level: pd.Series):\n",
    "    \"\"\"\n",
    "    weights_row_level must be aligned to df rows: len(weights) == len(df),\n",
    "    representing per-(date,ticker) portfolio weights.\n",
    "    \"\"\"\n",
    "    if len(weights_row_level) != len(df):\n",
    "        raise ValueError(f\"Expected weights length {len(df)}, got {len(weights_row_level)}\")\n",
    "\n",
    "    notes = []\n",
    "\n",
    "    # Pivot weights to (date x ticker)\n",
    "    W = df.assign(w=weights_row_level.values).pivot(index=\"date\", columns=\"ticker\", values=\"w\").fillna(0.0)\n",
    "\n",
    "    # Check 1: Execution realism (look-ahead hint)\n",
    "    notes.append(\"Execution realism: if signals use close-of-day data, shift weights by +1 day before applying returns.\")\n",
    "\n",
    "    # Check 2: Invested days (sparsity)\n",
    "    invested_days = (W.sum(axis=1) > 0).mean()\n",
    "    notes.append(f\"Sparsity: portfolio invested on {invested_days*100:.1f}% of days.\")\n",
    "\n",
    "    # Check 3: Concentration\n",
    "    max_weight = W.max(axis=1).mean()\n",
    "    notes.append(f\"Concentration: average max single-name weight = {max_weight:.2f} (lower is better).\")\n",
    "\n",
    "    # Check 4: Turnover\n",
    "    turnover = 0.5 * W.diff().abs().sum(axis=1)\n",
    "    notes.append(f\"Turnover: avg daily turnover = {turnover.mean():.3f}.\")\n",
    "\n",
    "    # Check 5: Universe stability (how many names held)\n",
    "    names_held = (W > 0).sum(axis=1)\n",
    "    notes.append(f\"Holdings: avg names held = {names_held.mean():.1f}, median = {names_held.median():.0f}.\")\n",
    "\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = generate_hybrid_weights(\n",
    "    df,\n",
    "    top_n=int(best[\"top_n\"]),\n",
    "    oversold_th=int(best[\"oversold_th\"]),\n",
    "    use_candle_confirm=bool(best[\"candle_confirm\"]),\n",
    "    use_trend_filter=bool(best[\"trend_filter\"])\n",
    ")\n",
    "\n",
    "reflection_notes = self_reflection_checks(df, best_weights)\n",
    "\n",
    "for n in reflection_notes:\n",
    "    print(\"-\", n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8984d",
   "metadata": {},
   "source": [
    "### Produce a “Research Memo” (Markdown + save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca00450",
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = f\"\"\"# Agentic Research Memo — Best Hybrid Candidate\n",
    "\n",
    "**Question / Intent:** {question}  \n",
    "**Router Decision:** {intent}  \n",
    "\n",
    "## Selected Candidate\n",
    "- **ID:** {best_key}\n",
    "- **Top N (fundamental selection):** {best['top_n']}\n",
    "- **Stochastic oversold threshold:** {best['oversold_th']}\n",
    "- **Candle confirmation:** {best['candle_confirm']}\n",
    "- **Trend filter (price > EMA20):** {best['trend_filter']}\n",
    "\n",
    "## Performance (Net of Costs)\n",
    "- CAGR: {best['cagr']:.2%}\n",
    "- Sharpe: {best['sharpe']:.2f}\n",
    "- Sortino: {best['sortino']:.2f}\n",
    "- Max Drawdown: {best['max_drawdown']:.2%}\n",
    "- Calmar: {best['calmar']:.2f}\n",
    "- Avg Turnover: {best['avg_turnover']:.3f}\n",
    "\n",
    "## Why this candidate won (Evaluator Summary)\n",
    "- Optimizes risk-adjusted return (Sharpe) while controlling drawdown and turnover.\n",
    "- Uses fundamentals for selection and technical signals for timing (reduces overtrading).\n",
    "\n",
    "## Self-Reflection / Caveats\n",
    "\"\"\" + \"\\n\".join([f\"- {n}\" for n in reflection_notes]) + \"\"\"\n",
    "\n",
    "## Next Improvements\n",
    "- Shift weights by 1 day for strict execution realism.\n",
    "- Add walk-forward splits and evaluate stability across regimes.\n",
    "- Add sector constraints to reduce hidden concentration risk.\n",
    "\"\"\"\n",
    "\n",
    "memo_path = os.path.join(REPORTS, \"agentic_research_memo.md\")\n",
    "with open(memo_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(memo)\n",
    "\n",
    "print(\"Saved memo:\", memo_path)\n",
    "print(\"\\n---\\n\")\n",
    "print(memo[:1200], \"...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-quant-researcher (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
