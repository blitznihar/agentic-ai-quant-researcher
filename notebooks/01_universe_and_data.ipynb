{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4b08be",
   "metadata": {},
   "source": [
    "# Universe and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52874421",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data sources (Phase 1: keep it simple)\n",
    "import yfinance as yf\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # notebooks/ -> repo root\n",
    "DATA_RAW = os.path.join(REPO_ROOT, \"data\", \"raw\")\n",
    "DATA_PROCESSED = os.path.join(REPO_ROOT, \"data\", \"processed\")\n",
    "DATA_CACHE = os.path.join(REPO_ROOT, \"data\", \"cache\")\n",
    "\n",
    "for p in [DATA_RAW, DATA_PROCESSED, DATA_CACHE]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Processed:\", DATA_PROCESSED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6fefd",
   "metadata": {},
   "source": [
    "### Universe definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a strong but manageable universe for Phase 1.\n",
    "# Tip: keep it 20–50 tickers so notebooks run fast.\n",
    "UNIVERSE = [\n",
    "    \"AAPL\",\"MSFT\",\"NVDA\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\n",
    "    \"JPM\",\"BAC\",\"GS\",\n",
    "    \"UNH\",\"JNJ\",\"PFE\",\n",
    "    \"XOM\",\"CVX\",\n",
    "    \"KO\",\"PEP\",\n",
    "    \"COST\",\"WMT\",\n",
    "    \"SPY\",\"QQQ\"\n",
    "]\n",
    "\n",
    "# Time range\n",
    "END = datetime.today().date()\n",
    "START = END - timedelta(days=365*8)  # 8 years of daily data\n",
    "\n",
    "print(\"Tickers:\", len(UNIVERSE))\n",
    "print(\"Start:\", START, \"End:\", END)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da25f7",
   "metadata": {},
   "source": [
    "### Download OHLCV (adjusted) + corporate actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ce1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ohlcv(tickers, start, end, interval=\"1d\"):\n",
    "    \"\"\"\n",
    "    Returns a multi-index columns DataFrame from yfinance:\n",
    "    columns like ('Close','AAPL'), etc.\n",
    "    \"\"\"\n",
    "    df = yf.download(\n",
    "        tickers=tickers,\n",
    "        start=str(start),\n",
    "        end=str(end),\n",
    "        interval=interval,\n",
    "        auto_adjust=False,  # we'll keep both raw + adjusted logic explicit\n",
    "        group_by=\"column\",\n",
    "        threads=True,\n",
    "        progress=False\n",
    "    )\n",
    "    return df\n",
    "\n",
    "ohlcv_raw = fetch_ohlcv(UNIVERSE, START, END)\n",
    "ohlcv_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22856879",
   "metadata": {},
   "source": [
    "### Normalize OHLCV into a tidy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_ohlcv(ohlcv):\n",
    "    \"\"\"\n",
    "    Convert yfinance multi-index OHLCV into tidy long-form dataframe.\n",
    "    \"\"\"\n",
    "    # yfinance returns columns like: Open, High, Low, Close, Adj Close, Volume\n",
    "    # with tickers on second level if multiple tickers.\n",
    "    if isinstance(ohlcv.columns, pd.MultiIndex):\n",
    "        tidy = (\n",
    "            ohlcv\n",
    "            .stack(level=1, future_stack=True)\n",
    "            .reset_index()\n",
    "            .rename(columns={\"level_1\":\"ticker\"})\n",
    "        )\n",
    "    else:\n",
    "        # single ticker case\n",
    "        tidy = ohlcv.reset_index()\n",
    "        tidy[\"ticker\"] = \"SINGLE\"\n",
    "    \n",
    "    \n",
    "    tidy = tidy.rename(columns={\n",
    "        \"Date\":\"date\",\n",
    "        \"Ticker\":\"ticker\",\n",
    "        \"Open\":\"open\",\n",
    "        \"High\":\"high\",\n",
    "        \"Low\":\"low\",\n",
    "        \"Close\":\"close\",\n",
    "        \"Adj Close\":\"adj_close\",\n",
    "        \"Volume\":\"volume\"\n",
    "    })\n",
    "    tidy[\"date\"] = pd.to_datetime(tidy[\"date\"])\n",
    "    tidy = tidy.sort_values([\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "    return tidy\n",
    "\n",
    "ohlcv = tidy_ohlcv(ohlcv_raw)\n",
    "ohlcv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fc22b",
   "metadata": {},
   "source": [
    "### Basic data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84949bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_report(df):\n",
    "    # missing values by column\n",
    "    missing = df.isna().mean().sort_values(ascending=False)\n",
    "    \n",
    "    # duplicates\n",
    "    dup = df.duplicated(subset=[\"date\",\"ticker\"]).sum()\n",
    "    \n",
    "    # per ticker coverage\n",
    "    coverage = df.groupby(\"ticker\")[\"date\"].agg([\"min\",\"max\",\"count\"])\n",
    "    return missing, dup, coverage\n",
    "\n",
    "missing, dup, coverage = quality_report(ohlcv)\n",
    "print(\"Duplicate rows (date,ticker):\", dup)\n",
    "display(missing.head(10))\n",
    "display(coverage.sort_values(\"count\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31213e14",
   "metadata": {},
   "source": [
    "### Fundamentals snapshot\n",
    "\n",
    "Fetching a small set of fundamentals per ticker:\n",
    "\n",
    "- market cap\n",
    "- trailing PE\n",
    "- forward PE (if available)\n",
    "- price-to-book\n",
    "- profit margins\n",
    "- revenue growth (if available)\n",
    "- debt/equity (if available)\n",
    "- dividend yield (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5543d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_fundamentals_snapshot(tickers, sleep_s=0.2):\n",
    "    rows = []\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            info = yf.Ticker(t).info\n",
    "            rows.append({\n",
    "                \"ticker\": t,\n",
    "                \"asof\": pd.Timestamp.utcnow(),\n",
    "                \"marketCap\": info.get(\"marketCap\"),\n",
    "                \"trailingPE\": info.get(\"trailingPE\"),\n",
    "                \"forwardPE\": info.get(\"forwardPE\"),\n",
    "                \"priceToBook\": info.get(\"priceToBook\"),\n",
    "                \"profitMargins\": info.get(\"profitMargins\"),\n",
    "                \"revenueGrowth\": info.get(\"revenueGrowth\"),\n",
    "                \"debtToEquity\": info.get(\"debtToEquity\"),\n",
    "                \"dividendYield\": info.get(\"dividendYield\"),\n",
    "                \"sector\": info.get(\"sector\"),\n",
    "                \"industry\": info.get(\"industry\"),\n",
    "            })\n",
    "            time.sleep(sleep_s)\n",
    "        except Exception as e:\n",
    "            rows.append({\"ticker\": t, \"asof\": pd.Timestamp.utcnow(), \"error\": str(e)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "fundamentals = fetch_fundamentals_snapshot(UNIVERSE)\n",
    "fundamentals.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de538b8",
   "metadata": {},
   "source": [
    "### Save artifacts to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642598cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_path = os.path.join(DATA_RAW, \"ohlcv.parquet\")\n",
    "fund_path = os.path.join(DATA_RAW, \"fundamentals_snapshot.parquet\")\n",
    "\n",
    "ohlcv.to_parquet(ohlcv_path, index=False)\n",
    "fundamentals.to_parquet(fund_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Saved:\", ohlcv_path)\n",
    "print(\"Saved:\", fund_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a459df",
   "metadata": {},
   "source": [
    "### Quick sanity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity plot: close price for SPY and QQQ\n",
    "plot_df = ohlcv[ohlcv[\"ticker\"].isin([\"SPY\",\"QQQ\"])].pivot(index=\"date\", columns=\"ticker\", values=\"adj_close\")\n",
    "\n",
    "plot_df.plot(title=\"Adjusted Close (SPY vs QQQ)\", figsize=(10,4))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d4baa",
   "metadata": {},
   "source": [
    "### “Processed” dataset stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff873e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = ohlcv.merge(fundamentals.drop(columns=[\"asof\"]), on=\"ticker\", how=\"left\")\n",
    "\n",
    "processed_path = os.path.join(DATA_PROCESSED, \"market_merged.parquet\")\n",
    "processed.to_parquet(processed_path, index=False)\n",
    "\n",
    "processed.head(), processed_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-quant-researcher (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
