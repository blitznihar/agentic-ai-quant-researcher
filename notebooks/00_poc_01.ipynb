{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c95410e",
   "metadata": {},
   "source": [
    "# Gradio and Chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc722bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b4b64",
   "metadata": {},
   "source": [
    "# Generic Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.load_chat(\"http://localhost:11434/v1/\", model=\"gemma3:1b\", token=\"***\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32044f5b",
   "metadata": {},
   "source": [
    "# Apple Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a polite, concise virtual assistant for Apple Support. \"\n",
    "    \"Offer troubleshooting steps for Apple devices (iPhone, iPad, Mac, Watch, AirPods). \"\n",
    "    \"Do not request personal data or serial numbers. \"\n",
    "    \"For account, billing, or repair needs, direct users to the official Apple Support channels.\"\n",
    ")\n",
    "\n",
    "BASE_URL = \"http://localhost:11434/v1/\"\n",
    "MODEL = \"gemma3:1b\"\n",
    "API_KEY = os.getenv(\"OLLAMA_TOKEN\", \"ollama\")\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "\n",
    "def normalize_history(history):\n",
    "    \"\"\"\n",
    "    Supports multiple Gradio history formats:\n",
    "    1) [(user, assistant), ...]\n",
    "    2) [{\"role\":\"user\",\"content\":\"...\"}, {\"role\":\"assistant\",\"content\":\"...\"}, ...]\n",
    "    3) [{\"role\":\"user\",\"content\":\"...\"}, ...] (some variants)\n",
    "    4) [{\"type\":\"human\"/\"ai\",\"content\":\"...\"}] (older/internal variants)\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    if not history:\n",
    "        return messages\n",
    "\n",
    "    # Case: messages already\n",
    "    if isinstance(history, list) and isinstance(history[0], dict):\n",
    "        for m in history:\n",
    "            role = m.get(\"role\")\n",
    "            content = m.get(\"content\")\n",
    "\n",
    "            # Some variants use \"type\" instead of \"role\"\n",
    "            if role is None and \"type\" in m:\n",
    "                role = \"user\" if m[\"type\"] in (\"human\", \"user\") else \"assistant\"\n",
    "\n",
    "            if role in (\"user\", \"assistant\") and content is not None:\n",
    "                messages.append({\"role\": role, \"content\": content})\n",
    "        return messages\n",
    "\n",
    "    # Case: tuple pairs\n",
    "    if isinstance(history, list):\n",
    "        for item in history:\n",
    "            # could be (user, assistant) or sometimes longer tuples\n",
    "            if isinstance(item, (tuple, list)) and len(item) >= 2:\n",
    "                user_msg = item[0]\n",
    "                assistant_msg = item[1]\n",
    "                if user_msg:\n",
    "                    messages.append({\"role\": \"user\", \"content\": str(user_msg)})\n",
    "                if assistant_msg:\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": str(assistant_msg)})\n",
    "        return messages\n",
    "\n",
    "    return messages\n",
    "\n",
    "def chat_fn(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    messages.extend(normalize_history(history))\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_fn,\n",
    "    title=\"Apple Support Assistant\",\n",
    "    description=\"Polite, concise troubleshooting help for Apple devices.\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdd95c",
   "metadata": {},
   "source": [
    "# Financial Advisor and Investment advisor chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f471d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a knowledgeable, calm, and structured virtual advisor for users in the United States, \"\n",
    "    \"specializing in personal finance, retirement planning, life insurance, annuities, \"\n",
    "    \"tax-aware investing, and stock market portfolio construction. \"\n",
    "    \"\\n\\n\"\n",
    "    \"PRIMARY OBJECTIVE:\\n\"\n",
    "    \"1) Understand the user’s goal(s) and constraints.\\n\"\n",
    "    \"2) Derive a risk profile (risk tolerance + risk capacity) and time horizon.\\n\"\n",
    "    \"3) Provide specific, actionable options such as model allocations, example tickers/ETFs, \"\n",
    "    \"and insurance/annuity product-type recommendations appropriate to the stated profile.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"DISCOVERY (ASK BEFORE RECOMMENDING):\\n\"\n",
    "    \"Ask concise questions to determine:\\n\"\n",
    "    \"- Goal: retirement, income, growth, preservation, education, home, etc.\\n\"\n",
    "    \"- Time horizon(s): <3y, 3–7y, 7–15y, 15y+.\\n\"\n",
    "    \"- Risk tolerance: comfort with drawdowns (e.g., -10%, -20%, -35%), and reaction to volatility.\\n\"\n",
    "    \"- Risk capacity: income stability, emergency fund, debt, near-term cash needs.\\n\"\n",
    "    \"- Current situation: age range, employment, dependents, existing accounts (401k/IRA/HSA/taxable), \"\n",
    "    \"and approximate investable amount.\\n\"\n",
    "    \"- Tax context (USA): filing status, bracket range, state tax presence, capital gains horizon.\\n\"\n",
    "    \"- Preferences/constraints: ESG, dividends, no-crypto, avoid single stocks, etc.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"RISK PROFILING OUTPUT:\\n\"\n",
    "    \"Summarize the derived profile as one of: Conservative, Moderately Conservative, Balanced, \"\n",
    "    \"Growth, Aggressive Growth, and explain why (time horizon + drawdown tolerance + capacity). \"\n",
    "    \"\\n\\n\"\n",
    "    \"PORTFOLIO GUIDANCE (BE SPECIFIC):\\n\"\n",
    "    \"Provide 2–3 specific model portfolio options aligned to the risk profile using diversified, \"\n",
    "    \"liquid instruments typically available to U.S. investors (e.g., broad-market ETFs, bond ETFs, \"\n",
    "    \"T-bill ETFs/money market guidance). Include example ticker symbols and target percentages, \"\n",
    "    \"plus simple rebalancing rules (e.g., quarterly/annual or threshold-based). \"\n",
    "    \"Discuss tradeoffs (cost, diversification, volatility, sequence-of-returns risk). \"\n",
    "    \"Avoid leverage unless the user explicitly asks and demonstrates sophistication.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"INSURANCE & ANNUITIES GUIDANCE (BE SPECIFIC ON TYPES):\\n\"\n",
    "    \"If the user’s goal includes protection or guaranteed income, recommend suitable product TYPES \"\n",
    "    \"(e.g., term life vs permanent, SPIA/DIA/fixed annuity/fixed indexed annuity/variable annuity) \"\n",
    "    \"and explain when each is appropriate, key riders (income rider, LTC rider), key fees, surrender \"\n",
    "    \"periods, and the primary risks. Do not invent insurer-specific quotes. If costs/returns are needed, \"\n",
    "    \"use ranges and clearly label as estimates.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"USA TAX-AWARE GUIDANCE:\\n\"\n",
    "    \"Provide high-level tax planning ideas relevant to the user’s profile: \"\n",
    "    \"401(k)/403(b)/457, Traditional vs Roth IRA, Backdoor Roth (when relevant), HSA, \"\n",
    "    \"tax-loss harvesting, asset location (bonds in tax-advantaged, equities in taxable), \"\n",
    "    \"qualified dividends, long-term capital gains timing, and estimated tax considerations \"\n",
    "    \"for self-employment. \"\n",
    "    \"For LLC topics, explain when an LLC may help (liability, clean bookkeeping) and when tax benefits \"\n",
    "    \"come from the tax election/structure (sole prop vs S-corp election), payroll requirements, \"\n",
    "    \"reasonable compensation concept, and compliance costs. Always advise confirming with a CPA/EA.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"COMPLIANCE & SAFETY RULES:\\n\"\n",
    "    \"- You must include a brief disclaimer that you provide educational information and model examples, \"\n",
    "    \"not individualized legal/tax advice.\\n\"\n",
    "    \"- You must not guarantee returns or claim certainty.\\n\"\n",
    "    \"- You must not request highly sensitive personal data (SSN, account numbers).\\n\"\n",
    "    \"- If the user has complex situations (large net worth, tax residency issues, trusts, estate planning, \"\n",
    "    \"business sale, margin/leverage), recommend consulting a licensed professional.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"COMMUNICATION STYLE:\\n\"\n",
    "    \"Be concise, structured, and practical. Use bullets and small tables when helpful. \"\n",
    "    \"When recommending, provide: (a) why it fits, (b) the specific allocation/options, \"\n",
    "    \"(c) key risks, (d) next steps the user can take today.\"\n",
    ")\n",
    "\n",
    "BASE_URL = \"http://localhost:11434/v1/\"\n",
    "MODEL = \"gemma3:1b\"\n",
    "API_KEY = os.getenv(\"OLLAMA_TOKEN\", \"ollama\")\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "\n",
    "def normalize_history(history):\n",
    "    \"\"\"\n",
    "    Supports multiple Gradio history formats:\n",
    "    1) [(user, assistant), ...]\n",
    "    2) [{\"role\":\"user\",\"content\":\"...\"}, {\"role\":\"assistant\",\"content\":\"...\"}, ...]\n",
    "    3) [{\"role\":\"user\",\"content\":\"...\"}, ...] (some variants)\n",
    "    4) [{\"type\":\"human\"/\"ai\",\"content\":\"...\"}] (older/internal variants)\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    if not history:\n",
    "        return messages\n",
    "\n",
    "    # Case: messages already\n",
    "    if isinstance(history, list) and isinstance(history[0], dict):\n",
    "        for m in history:\n",
    "            role = m.get(\"role\")\n",
    "            content = m.get(\"content\")\n",
    "\n",
    "            # Some variants use \"type\" instead of \"role\"\n",
    "            if role is None and \"type\" in m:\n",
    "                role = \"user\" if m[\"type\"] in (\"human\", \"user\") else \"assistant\"\n",
    "\n",
    "            if role in (\"user\", \"assistant\") and content is not None:\n",
    "                messages.append({\"role\": role, \"content\": content})\n",
    "        return messages\n",
    "\n",
    "    # Case: tuple pairs\n",
    "    if isinstance(history, list):\n",
    "        for item in history:\n",
    "            # could be (user, assistant) or sometimes longer tuples\n",
    "            if isinstance(item, (tuple, list)) and len(item) >= 2:\n",
    "                user_msg = item[0]\n",
    "                assistant_msg = item[1]\n",
    "                if user_msg:\n",
    "                    messages.append({\"role\": \"user\", \"content\": str(user_msg)})\n",
    "                if assistant_msg:\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": str(assistant_msg)})\n",
    "        return messages\n",
    "\n",
    "    return messages\n",
    "\n",
    "def chat_fn(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    messages.extend(normalize_history(history))\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_fn,\n",
    "    title=\"Financial Advisor and Investment Assistant\",\n",
    "    description=\"Polite, concise financial advice and investment assistance.\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-quant-researcher (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
